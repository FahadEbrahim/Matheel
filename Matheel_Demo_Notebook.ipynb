{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c58c099d-5b6c-411a-9f38-851320cd4b9f",
      "metadata": {
        "id": "c58c099d-5b6c-411a-9f38-851320cd4b9f"
      },
      "outputs": [],
      "source": [
        "!pip install gradio sentence-transformers numpy pandas rapidfuzz sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b80321b-96aa-4b64-a004-3c06fadfbe1a",
      "metadata": {
        "id": "6b80321b-96aa-4b64-a004-3c06fadfbe1a"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rapidfuzz.distance import Levenshtein, JaroWinkler\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from typing import List\n",
        "import zipfile\n",
        "import os\n",
        "import io\n",
        "\n",
        "def calculate_similarity(code1, code2, Ws, Wl, Wj, model_name):\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embedding1 = model.encode(code1)\n",
        "    embedding2 = model.encode(code2)\n",
        "    sim_similarity = util.cos_sim(embedding1, embedding2).item()\n",
        "    lev_ratio = Levenshtein.normalized_similarity(code1, code2)\n",
        "    jaro_winkler_ratio = JaroWinkler.normalized_similarity(code1, code2)\n",
        "    overall_similarity = Ws * sim_similarity + Wl * lev_ratio + Wj * jaro_winkler_ratio\n",
        "\n",
        "    return \"The similarity score between the two codes is: %.2f\" % overall_similarity\n",
        "\n",
        "def extract_and_read_compressed_file(file_path):\n",
        "    file_names = []\n",
        "    codes = []\n",
        "\n",
        "    if file_path.endswith('.zip'):\n",
        "        with zipfile.ZipFile(file_path, 'r') as z:\n",
        "            file_names = z.namelist()\n",
        "            codes = [z.read(file).decode('utf-8', errors='ignore') for file in file_names]\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type. Only .zip is supported.\")\n",
        "\n",
        "    return file_names, codes\n",
        "\n",
        "def filter_and_return_top(df, similarity_threshold,returned_results):\n",
        "    filtered_df = df[df['similarity_score'] > similarity_threshold]\n",
        "    return filtered_df.head(returned_results)\n",
        "\n",
        "def perform_paraphrase_mining(model, codes_list, weight_semantic, weight_levenshtein, weight_jaro_winkler):\n",
        "    return paraphrase_mining_with_combined_score(\n",
        "        model,\n",
        "        codes_list,\n",
        "        weight_semantic=weight_semantic,\n",
        "        weight_levenshtein=weight_levenshtein,\n",
        "        weight_jaro_winkler=weight_jaro_winkler\n",
        "    )\n",
        "\n",
        "def paraphrase_mining_with_combined_score(\n",
        "    model,\n",
        "    sentences: List[str],\n",
        "    show_progress_bar: bool = False,\n",
        "    weight_semantic: float = 1.0,\n",
        "    weight_levenshtein: float = 0.0,\n",
        "    weight_jaro_winkler: float = 0.0\n",
        "):\n",
        "    embeddings = model.encode(\n",
        "        sentences, show_progress_bar=show_progress_bar, convert_to_tensor=True)\n",
        "    paraphrases = util.paraphrase_mining_embeddings(embeddings, score_function=util.cos_sim)\n",
        "\n",
        "    results = []\n",
        "    for score, i, j in paraphrases:\n",
        "        lev_ratio = Levenshtein.normalized_similarity(sentences[i], sentences[j])\n",
        "        jaro_winkler_ratio = JaroWinkler.normalized_similarity(sentences[i], sentences[j])\n",
        "\n",
        "        combined_score = (weight_semantic * score) + \\\n",
        "                         (weight_levenshtein * lev_ratio) + \\\n",
        "                         (weight_jaro_winkler * jaro_winkler_ratio)\n",
        "\n",
        "        results.append([combined_score, i, j])\n",
        "\n",
        "    results = sorted(results, key=lambda x: x[0], reverse=True)\n",
        "    return results\n",
        "\n",
        "def get_sim_list(zipped_file,Ws, Wl, Wj, model_name,threshold,number_results):\n",
        "    file_names, codes = extract_and_read_compressed_file(zipped_file)\n",
        "    model = SentenceTransformer(model_name)\n",
        "    code_pairs = perform_paraphrase_mining(model, codes,Ws, Wl, Wj)\n",
        "    pairs_results = []\n",
        "\n",
        "    for score, i, j in code_pairs:\n",
        "      pairs_results.append({\n",
        "        'file_name_1': file_names[i],\n",
        "        'file_name_2': file_names[j],\n",
        "        'similarity_score': score\n",
        "    })\n",
        "\n",
        "    similarity_df = pd.concat([pd.DataFrame(paraphrase_results)], ignore_index=True)\n",
        "    similarity_df = similarity_df.sort_values(by='similarity_score', ascending=False)\n",
        "    result = filter_and_return_top(similarity_df,threshold,number_results).round(2)\n",
        "\n",
        "    return result\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(\"Code Similarity\"):\n",
        "        code1 = gr.Textbox(label=\"Code 1\")\n",
        "        code2 = gr.Textbox(label=\"Code 2\")\n",
        "\n",
        "        with gr.Accordion(\"Weights and Models\", open=False):\n",
        "            Ws = gr.Slider(0, 1, value=0.7, label=\"Semantic Search Weight\", step=0.1)\n",
        "            Wl = gr.Slider(0, 1, value=0.3, label=\"Levenshiern Distance Weight\", step=0.1)\n",
        "            Wj = gr.Slider(0, 1, value=0.0, label=\"Jaro Winkler Weight\", step=0.1)\n",
        "            model_dropdown = gr.Dropdown(\n",
        "            [(\"codebert\", \"microsoft/codebert-base\"),\n",
        "             (\"graphcodebert\", \"microsoft/graphcodebert-base\"),\n",
        "             (\"UnixCoder\", \"microsoft/unixcoder-base-unimodal\"),\n",
        "             (\"CodeBERTa\", \"huggingface/CodeBERTa-small-v1\"),\n",
        "             (\"CodeT5 small\", \"Salesforce/codet5-small\"),\n",
        "             (\"PLBART\", \"uclanlp/plbart-java-cs\"),],\n",
        "            label=\"Select Model\",\n",
        "            value= \"uclanlp/plbart-java-cs\"\n",
        "            )\n",
        "\n",
        "        output = gr.Textbox(label=\"Similarity Score\")\n",
        "\n",
        "        def update_weights(Ws, Wl, Wj):\n",
        "            total = Ws + Wl + Wj\n",
        "            if total != 1:\n",
        "                Wj = 1 - (Ws + Wl)\n",
        "            return Ws, Wl, Wj\n",
        "\n",
        "        Ws.change(update_weights, [Ws, Wl, Wj], [Ws, Wl, Wj])\n",
        "        Wl.change(update_weights, [Ws, Wl, Wj], [Ws, Wl, Wj])\n",
        "        Wj.change(update_weights, [Ws, Wl, Wj], [Ws, Wl, Wj])\n",
        "\n",
        "        calculate_btn = gr.Button(\"Calculate Similarity\")\n",
        "        calculate_btn.click(calculate_similarity, inputs=[code1, code2, Ws, Wl, Wj, model_dropdown], outputs=output)\n",
        "\n",
        "    with gr.Tab(\"File Upload\"):\n",
        "        file_uploader = gr.File(label=\"Upload a Zip file\",file_types=[\".zip\"])\n",
        "\n",
        "        with gr.Accordion(\"Weights and Models\", open=False):\n",
        "            Ws = gr.Slider(0, 1, value=0.7, label=\"Semantic Search Weight\", step=0.1)\n",
        "            Wl = gr.Slider(0, 1, value=0.3, label=\"Levenshiern Distance Weight\", step=0.1)\n",
        "            Wj = gr.Slider(0, 1, value=0.0, label=\"Jaro Winkler Weight\", step=0.1)\n",
        "            model_dropdown = gr.Dropdown(\n",
        "            [(\"codebert\", \"microsoft/codebert-base\"),\n",
        "             (\"graphcodebert\", \"microsoft/graphcodebert-base\"),\n",
        "             (\"UnixCoder\", \"microsoft/unixcoder-base-unimodal\"),\n",
        "             (\"CodeBERTa\", \"huggingface/CodeBERTa-small-v1\"),\n",
        "             (\"CodeT5 small\", \"Salesforce/codet5-small\"),\n",
        "             (\"PLBART\", \"uclanlp/plbart-java-cs\"),],\n",
        "            label=\"Select Model\",\n",
        "            value= \"uclanlp/plbart-java-cs\"\n",
        "            )\n",
        "            threshold = gr.Slider(0, 1, value=0, label=\"Threshold\", step=0.01)\n",
        "            number_results = gr.Slider(1, 1000, value=10, label=\"Number of Returned pairs\", step=1)\n",
        "\n",
        "        df_output = gr.Dataframe(label=\"Uploaded Data\")\n",
        "\n",
        "        process_btn = gr.Button(\"Process File\")\n",
        "        process_btn.click(get_sim_list, inputs=[file_uploader, Ws, Wl, Wj, model_dropdown,threshold,number_results], outputs=df_output)\n",
        "\n",
        "demo.launch(show_error=True,share=True,debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290f53bb-56cb-4760-aefd-b80b47d56846",
      "metadata": {
        "id": "290f53bb-56cb-4760-aefd-b80b47d56846"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}